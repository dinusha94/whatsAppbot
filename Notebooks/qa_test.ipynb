{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings,ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY=os.environ[\"GOOGLE_API_KEY\"]\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_context(vectordb,question):\n",
    "    docs = vectordb.similarity_search(question,k=3)\n",
    "    doc_list= []\n",
    "    context=\"\"\n",
    "    for i in range(len(docs)):\n",
    "        #print(docs[i].page_content)\n",
    "        context =context + docs[i].page_content +\"\\n\"\n",
    "    for doc in docs:\n",
    "        #print(doc.metadata)\n",
    "        doc_list.append(doc.metadata)\n",
    "    return context,doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    max_tokens=250,\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that answers questions provided by the user. You must use the available {context} for providing answers. Do not provide any other answers if they are not present in {context}.\",\n",
    "        ),\n",
    "        (\"human\", \"context:{context}\\nquestion:{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "question= \"Hi can you tell some solar panel issues i can encounter?\"\n",
    "context,doc_list=gen_context(vectordb,question)\n",
    "ai_msg=chain.invoke({\n",
    "    \"question\": question,\n",
    "    \"context\": context\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some solar panel issues you might encounter:\n",
      "\n",
      "* **Dust on Solar Panel:**  Dust can accumulate on the panels, reducing their efficiency. Regular cleaning is important.\n",
      "* **Connection issue with main board:**  The wiring connecting the panels to the main board can become loose or damaged.\n",
      "* **Solar Panel Damage:**  Physical damage to the panels, such as cracks or broken glass, can significantly impact their performance. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii.\n",
      "Current\n",
      "sensor\n",
      "not\n",
      "working\n",
      "iii.\n",
      "Motor\n",
      "is\n",
      "not\n",
      "working\n",
      "d.\n",
      "Malfunction\n",
      "of\n",
      "Valve\n",
      "device\n",
      "i.\n",
      "Valve\n",
      "is\n",
      "damaged\n",
      "ii.\n",
      "Valve\n",
      "is\n",
      "not\n",
      "fully\n",
      "open\n",
      "4.\n",
      "SolarTrack\n",
      "a.\n",
      "Internet\n",
      "is\n",
      "not\n",
      "working\n",
      "i.\n",
      "Connection\n",
      "is\n",
      "disconnected\n",
      "ii.\n",
      "Firewall\n",
      "issues\n",
      "b.\n",
      "Inverter\n",
      "Modbus\n",
      "not\n",
      "working\n",
      "i.\n",
      "Inverter\n",
      "is\n",
      "off\n",
      "ii.\n",
      "Modbus\n",
      "is\n",
      "damaged\n",
      "iii.\n",
      "Switch\n",
      "is\n",
      "damaged\n",
      "iv.\n",
      "Inverter\n",
      "IP\n",
      "configurations\n",
      "changed\n",
      "c.\n",
      "Main\n",
      "board\n",
      "issue\n",
      "i.\n",
      "Memory\n",
      "overflow\n",
      "ii.\n",
      "Stuck\n",
      "in\n",
      "program\n",
      "iii.\n",
      "Heat\n",
      "issue\n",
      "in\n",
      "the\n",
      "Main\n",
      "board\n",
      "d.\n",
      "Device\n",
      "is\n",
      "restarted\n",
      "Solutions\n",
      "for\n",
      "those\n",
      "Failure\n",
      "Scenarios\n",
      "Device\n",
      "Failure\n",
      "scenarios\n",
      "1.\n",
      "Common\n",
      ":\n",
      "a.\n",
      "GSM\n",
      "connection\n",
      "failed\n",
      "i.\n",
      "SIM\n",
      "damaged\n",
      "ii.\n",
      "GSM\n",
      "module\n",
      "damaged\n",
      "iii.\n",
      "GSM\n",
      "module\n",
      "loss\n",
      "connection\n",
      "with\n",
      "main\n",
      "board\n",
      "iv.\n",
      "Connection\n",
      "disconnected\n",
      "due\n",
      "to\n",
      "payment\n",
      "issue\n",
      "v.\n",
      "GSM\n",
      "capacitor\n",
      "damaged\n",
      "b.\n",
      "Data\n",
      "drops\n",
      "i.\n",
      "Coverage\n",
      "issue\n",
      "c.\n",
      "Battery\n",
      "charging\n",
      "reducing\n",
      "d.\n",
      "Battery\n",
      "dead\n",
      "i.\n",
      "Direct\n",
      "Power\n",
      "source\n",
      "is\n",
      "off\n",
      "ii.\n",
      "Battery\n",
      "damaged\n",
      "e.\n",
      "Internal\n",
      "temperature\n",
      "is\n",
      "increasing\n",
      "f.\n",
      "Main\n",
      "board\n",
      "failed\n",
      "i.\n",
      "Internal\n",
      "temperature\n",
      "is\n",
      "high\n",
      "ii.\n",
      "Water\n",
      "inside\n",
      "g.\n",
      "Server\n",
      "down\n",
      "i.\n",
      "MQTT\n",
      "Broker\n",
      "down\n",
      "ii.\n",
      "App\n",
      "Server\n",
      "down\n",
      "2.\n",
      "Polar\n",
      ":\n",
      "a.\n",
      "Direct\n",
      "Power\n",
      "Source\n",
      "(12/24V)\n",
      "is\n",
      "powered\n",
      "off\n",
      "or\n",
      "removed\n",
      "b.\n",
      "Temperature\n",
      "sensor\n",
      "is\n",
      "malfunctioning\n",
      "(\n",
      "-127\n",
      ",\n",
      "+84\n",
      ")\n",
      "i.\n",
      "Chip\n",
      "failed\n",
      "ii.\n",
      "Sensor\n",
      "wire\n",
      "damaged\n",
      "iii.\n",
      "Connection\n",
      "issue\n",
      "with\n",
      "main\n",
      "board\n",
      "3.\n",
      "SenzAgro\n",
      "a.\n",
      "Solar\n",
      "Panel\n",
      "issues\n",
      "i.\n",
      "Dust\n",
      "on\n",
      "Solar\n",
      "Panel\n",
      "ii.\n",
      "Connection\n",
      "issue\n",
      "with\n",
      "main\n",
      "board\n",
      "iii.\n",
      "Solar\n",
      "Panel\n",
      "Damage\n",
      "b.\n",
      "Malfunction\n",
      "of\n",
      "sensors\n",
      "i.\n",
      "Irrometer\n",
      "1.\n",
      "Sensor\n",
      "is\n",
      "outside\n",
      "soil\n",
      "ii.\n",
      "Temperature\n",
      "sensor\n",
      "1.\n",
      "As\n",
      "mentioned\n",
      "in\n",
      "Polar\n",
      "iii.\n",
      "Humidity\n",
      "sensor\n",
      "1.\n",
      "Alway\n",
      "100%\n",
      "showing\n",
      "iv.\n",
      "Light\n",
      "sensor\n",
      "1.\n",
      "Dust\n",
      "on\n",
      "Cover\n",
      "c.\n",
      "Malfunction\n",
      "of\n",
      "Motor\n",
      "Device\n",
      "i.\n",
      "Relay\n",
      "damaged\n",
      "Humanoid\n",
      "Conversational\n",
      "Module\n",
      "1.\n",
      "First\n",
      "Message\n",
      "or\n",
      "Conversation\n",
      ":\n",
      "a.\n",
      "Failure\n",
      "Scenarios\n",
      "→\n",
      "RootCause\n",
      "Analysis\n",
      "b.\n",
      "It\n",
      "should\n",
      "include\n",
      "farmer\n",
      "name\n",
      "“Hi\n",
      "name”\n",
      "c.\n",
      "Instead\n",
      "of\n",
      "ID,\n",
      "use\n",
      "name\n",
      "2.\n",
      "Query\n",
      "1\n",
      ":\n",
      "Show\n",
      "me\n",
      "the\n",
      "graph\n",
      "[\n",
      "Graph\n",
      "Snapshot\n",
      "within\n",
      "the\n",
      "failure\n",
      "time\n",
      "period]\n",
      "3.\n",
      "Query\n",
      "2\n",
      ":\n",
      "When\n",
      "did\n",
      "the\n",
      "issue\n",
      "start\n",
      "?\n",
      "4.\n",
      "Query\n",
      "3\n",
      ":\n",
      "Show\n",
      "me\n",
      "the\n",
      "data\n",
      "log\n",
      "from\n",
      "the\n",
      "server?\n",
      "Asking\n",
      "Customers\n",
      ":\n",
      "1.\n",
      "System\n",
      "Questions\n",
      ":\n",
      "Eg\n",
      ":\n",
      "Is\n",
      "it\n",
      "raining\n",
      "there?\n",
      "2.\n",
      "Is\n",
      "there\n",
      "no\n",
      "power\n",
      "in\n",
      "the\n",
      "farm\n",
      "now?\n",
      "3.\n",
      "Did\n",
      "you\n",
      "clean\n",
      "solar\n",
      "panels\n",
      "recently?\n",
      "\n",
      "{'page': 1, 'source': 'pdf_chat/Test_Automation .pdf'}\n",
      "{'page': 0, 'source': 'pdf_chat/Test_Automation .pdf'}\n",
      "{'page': 2, 'source': 'pdf_chat/Test_Automation .pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(context)\n",
    "for i in range(len(doc_list)):\n",
    "    print(doc_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qa_system import initialise_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have one record regarding solar panels.\n",
      "\n",
      "- **Record ID:** 1\n",
      "- **Device ID:** 101\n",
      "- **Device Name:** Solar Panel\n",
      "- **Description:** There are dusts in the solar panel.\n",
      "- **Notifier Date Time:** 2024-07-31 11:37:19 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question= \"Can you give me all the records regarding solar panels?\"\n",
    "result = initialise_qa(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a database assistant. A user has a SQLite database with a table called 'Records'.\n",
    "The table has the following columns: records_id, device_id, device_name, description, notifier_date_time.\n",
    "If the user query request anything that does not include the database, then provide your as None.\n",
    "Do not generate any other than the SQL query required.\n",
    "\n",
    "\n",
    "Please generate an SQL query to retrieve records based on the following user request:\n",
    "{user_request}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"user_request\"])\n",
    "\n",
    "# Create the LangChain\n",
    "chain = prompt| llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sql_query(query):\n",
    "    # Remove triple backticks and surrounding whitespace\n",
    "    return query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AIMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# User request\u001b[39;00m\n\u001b[1;32m     15\u001b[0m user_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieve all records for device_id 101\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m results \u001b[38;5;241m=\u001b[39m query_database(user_request)\n",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m, in \u001b[0;36mquery_database\u001b[0;34m(user_request)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_database\u001b[39m(user_request):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Generate the SQL query\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_request\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_request})\n\u001b[0;32m----> 4\u001b[0m     generated_query \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated SQL Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Connect to the database\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'AIMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def query_database(user_request):\n",
    "    # Generate the SQL query\n",
    "    response = chain.invoke({\"user_request\": user_request})\n",
    "    generated_query = response[\"text\"].strip()\n",
    "    print(f\"Generated SQL Query: {generated_query}\")\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    df = pd.read_sql_query(generated_query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "# User request\n",
    "user_request = \"Retrieve all records for device_id 101\"\n",
    "results = query_database(user_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: ```sql\n",
      "SELECT * FROM Records WHERE description LIKE '%bug infestation%'\n",
      "```\n",
      "Cleaned SQL Query: SELECT * FROM Records WHERE description LIKE '%bug infestation%'\n"
     ]
    }
   ],
   "source": [
    "user_request = \"What is the solution for bug infestation\"\n",
    "response = chain.invoke({\"user_request\": user_request})\n",
    "generated_query = response.content.strip()\n",
    "print(f\"Generated SQL Query: {generated_query}\")\n",
    "cleaned_query = clean_sql_query(generated_query)\n",
    "print(f\"Cleaned SQL Query: {cleaned_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>records_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>device_name</th>\n",
       "      <th>description</th>\n",
       "      <th>notifier_date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [records_id, device_id, device_name, description, notifier_date_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(database_path)\n",
    "df = pd.read_sql_query(cleaned_query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert DataFrame to text\n",
    "def dataframe_to_text(df):\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        rows.append(f\"Record ID: {row['records_id']}, Device ID: {row['device_id']}, Device Name: {row['device_name']}, Description: {row['description']}, Notifier Date Time: {row['notifier_date_time']}\")\n",
    "    return \"\\n\".join(rows)\n",
    "\n",
    "\n",
    "# Define the prompt template for generating descriptions\n",
    "desc_prompt_template = \"\"\"\n",
    "You are an assistant that summarizes database records. If the records contain None, then you shall provide the answer as None. Please provide a bulleted description for each record given below:\n",
    "\n",
    "{records}\n",
    "\"\"\"\n",
    "\n",
    "desc_prompt = PromptTemplate(template=desc_prompt_template, input_variables=[\"records\"])\n",
    "# Create the LangChain for generating descriptions\n",
    "desc_chain = desc_prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_text = dataframe_to_text(df)\n",
    "records_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the database records you would like me to summarize. I'm ready to help! 😊 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = desc_chain.invoke({\"records\": records_text})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.records import records_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Hi can you give me recent records?\"\n",
    "result = records_output(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Record ID:** 1\n",
      "- **Device ID:** 3\n",
      "- **Device Name:** Device_B\n",
      "- **Description:** This is a test description\n",
      "- **Notifier Date Time:** 2024-07-31 11:05:05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
