{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from autogen import ConversableAgent\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings,ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY=os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"model\": \"gemini-1.5-flash\",\n",
    "              \"api_key\": GOOGLE_API_KEY,\n",
    "              \"api_type\": \"google\"}\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "genai_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(\n",
    "                api_key=GOOGLE_API_KEY,\n",
    "                model_name=\"models/embedding-001\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_config = {\n",
    "    \"task\" : \"qa\",\n",
    "    \"model\" : llm_config[\"model\"],\n",
    "    \"client\": chromadb.PersistentClient(path=\"docs/chroma\"),\n",
    "    \"embedding_function\" : genai_ef,\n",
    "    \"chunk_token_size\": 2000,\n",
    "    \"vector_db\": \"chroma\",\n",
    "    \"docs_path\" : [\"/home/shaheem/Documents/Project files/Notification system/pdf_chat/Test_Automation_questions.pdf\"],\n",
    "    \"overwrite\": False,\n",
    "    \"get_or_create\": True \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_proxy_agent = RetrieveUserProxyAgent(\n",
    "    name=\"rag_proxy_agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    retrieve_config=retriever_config,\n",
    "    code_execution_config=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_assistant =RetrieveAssistantAgent(\n",
    "    name=\"rag_assistant\",\n",
    "    system_message=\"You are a helpful AI assistant that retrives the context\",\n",
    "    llm_config={\n",
    "        \"timeout\":600,\n",
    "        \"config_list\":[llm_config]\n",
    "    }\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the common causes of Device Failure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 19:33:36,267 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - \u001b[32mUse the existing collection `autogen-docs`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 19:33:36,567 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - Found 1 chunks.\u001b[0m\n",
      "Model gemini-1.5-flash not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDB returns doc_ids:  [['938b583d']]\n",
      "\u001b[32mAdding content of doc 938b583d to context.\u001b[0m\n",
      "\u001b[33mrag_proxy_agent\u001b[0m (to rag_assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "You must give as short an answer as possible.\n",
      "\n",
      "User's question is: What are the common causes of Device Failure\n",
      "\n",
      "Context is: Device Failure scenarios for the systems\n",
      "1. Polar\n",
      "Failure case:- Direct power source is power off or removed\n",
      "Question :- Is the device's adapter AC current connected?\n",
      "Failure case:- Temparature sensor is malfunctioning ○ Question :- Is there a potal solwing sensor error? ○ Question :- Is sensor wire damaged?\n",
      "2. Common\n",
      "Failure case:- SIM damaged\n",
      "Question :- Is water present inside the sensor/are there rust inside the sensor circuitry\n",
      "Failure case:- GSM module damaged\n",
      "Question :- Is there an LED blinking within the device? ○ Question :- Is there water inside the device? ○ Question :- Is sensor wire damaged?\n",
      "Failure Case:- GSM module loss connection with main board\n",
      "Question :- Is the board's LED working? ○ Question :- Is the device's GSM LED off?\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mrag_assistant\u001b[0m (to rag_proxy_agent):\n",
      "\n",
      "UPDATE CONTEXT \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32mUpdating context and resetting conversation.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDB returns doc_ids:  [['938b583d']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDB returns doc_ids:  [['938b583d']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 7 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDB returns doc_ids:  [['938b583d']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 9 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDB returns doc_ids:  [['938b583d']]\n",
      "\u001b[32mNo more context, will terminate.\u001b[0m\n",
      "\u001b[33mrag_proxy_agent\u001b[0m (to rag_assistant):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result=rag_proxy_agent.initiate_chat(rag_assistant,\n",
    "                              problem=query,\n",
    "                              n_results=1,\n",
    "                              message=rag_proxy_agent.message_generator,\n",
    "                              max_turns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct power source is power off or removed, temperature sensor is malfunctioning, SIM damaged, GSM module damaged, GSM module loss connection with main board. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rag_proxy_agent.last_message()[\"content\"]\n",
    "print(rag_assistant.last_message()['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\\ncontext provided by the user.\\nIf you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\\nYou must give as short an answer as possible.\\n\\nUser's question is: What are the possible causes of Device Failure\\n\\nContext is: Device Failure scenarios for the systems\\n1. Polar\\nFailure case:- Direct power source is power off or removed\\nQuestion :- Is the device's adapter AC current connected?\\nFailure case:- Temparature sensor is malfunctioning ○ Question :- Is there a potal solwing sensor error? ○ Question :- Is sensor wire damaged?\\n2. Common\\nFailure case:- SIM damaged\\nQuestion :- Is water present inside the sensor/are there rust inside the sensor circuitry\\nFailure case:- GSM module damaged\\nQuestion :- Is there an LED blinking within the device? ○ Question :- Is there water inside the device? ○ Question :- Is sensor wire damaged?\\nFailure Case:- GSM module loss connection with main board\\nQuestion :- Is the board's LED working? ○ Question :- Is the device's GSM LED off?\\n\\n\", 'role': 'assistant'}, {'content': '- Direct power source is off or removed\\n- Temperature sensor is malfunctioning\\n- SIM damaged\\n- GSM module damaged\\n- GSM module loss connection with main board \\n', 'role': 'user'}], summary='- Direct power source is off or removed\\n- Temperature sensor is malfunctioning\\n- SIM damaged\\n- GSM module damaged\\n- GSM module loss connection with main board \\n', cost={'usage_including_cached_inference': {'total_cost': 0.002562, 'gemini-1.5-flash': {'cost': 0.002562, 'prompt_tokens': 261, 'completion_tokens': 35, 'total_tokens': 296}}, 'usage_excluding_cached_inference': {'total_cost': 0.002562, 'gemini-1.5-flash': {'cost': 0.002562, 'prompt_tokens': 261, 'completion_tokens': 35, 'total_tokens': 296}}}, human_input=[])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
